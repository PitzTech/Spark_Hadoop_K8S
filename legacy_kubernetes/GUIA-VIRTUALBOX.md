# Guia de ConfiguraÃ§Ã£o VirtualBox para Cluster Kubernetes

## ğŸ–¥ï¸ ConfiguraÃ§Ã£o das VMs

### 1. Criar 3 VMs Ubuntu Server

**EspecificaÃ§Ãµes mÃ­nimas por VM:**
- **RAM**: 4GB (Master), 2GB (Workers)
- **CPU**: 2 cores (Master), 1 core (Workers)
- **Disco**: 20GB
- **OS**: Ubuntu Server 22.04 LTS

### 2. ConfiguraÃ§Ã£o de Rede

**Para cada VM, configure 2 adaptadores de rede:**

#### Adaptador 1 (NAT) - Para acesso Ã  internet
- Tipo: NAT
- Usado para: Download de pacotes, imagens Docker

#### Adaptador 2 (Host-Only ou Bridged) - Para comunicaÃ§Ã£o entre VMs
- Tipo: Rede interna ou Host-Only
- Usado para: ComunicaÃ§Ã£o do cluster Kubernetes

### 3. Redirecionamento de Portas (Port Forwarding)

**Configure no VirtualBox para a VM Master:**

1. **VM Master â†’ ConfiguraÃ§Ãµes â†’ Rede â†’ Adaptador 1 â†’ AvanÃ§ado â†’ Redirecionamento de Portas**

|       Nome      | Protocolo | IP Host | Porta Host | IP Convidado | Porta Convidado |
|-----------------|-----------|---------|------------|--------------|-----------------|
| spark-master    |    TCP    |         |    8080    |              |      30080      |
| namenode        |    TCP    |         |    9870    |              |      30870      |
| resourcemanager |    TCP    |         |    8088    |              |      30088      |
| nodemanager     |    TCP    |         |    8042    |              |      30042      |
| jupyter         |    TCP    |         |    8888    |              |      30888      |
| history-server  |    TCP    |         |    18080   |              |      31080      |
| fastapi         |    TCP    |         |    8000    |              |      30000      |
| kubernetes-api  |    TCP    |         |    6443    |              |      6443       |

## ğŸš€ ExecuÃ§Ã£o do Script

### 1. VM Master (primeira VM)

```bash
# Na VM Master
sudo chmod +x fix-containerd.sh
sudo ./fix-containerd.sh

sudo chmod +x auto-setup-k8s.sh
sudo ./auto-setup-k8s.sh

# Selecionar: 1 (Master)
```

**O script irÃ¡:**
- âœ… Instalar Docker, Kubernetes
- âœ… Inicializar cluster como master
- âœ… Fazer deploy do cluster Hadoop/Spark
- âœ… Escalar workers automaticamente
- âœ… Mostrar URLs de acesso
- âœ… Fornecer comando para workers

### 2. VMs Workers (segunda e terceira VMs)

```bash
# Em cada VM Worker
sudo chmod +x fix-containerd.sh
sudo ./fix-containerd.sh

sudo chmod +x auto-setup-k8s.sh
sudo ./auto-setup-k8s.sh

# Selecionar: 2 (Worker)
# Inserir comando join fornecido pelo master
```

## ğŸŒ Acessar Interfaces (Windows Host)

ApÃ³s o setup completo, acesse pelo navegador do Windows:

- **Spark Master UI**: http://localhost:8080
- **Hadoop NameNode**: http://localhost:9870
- **YARN ResourceManager**: http://localhost:8088
- **NodeManager**: http://localhost:8042
- **Spark History**: http://localhost:18080
- **Jupyter Notebook**: http://localhost:8888
- **FastAPI**: http://localhost:8000

## ğŸ”§ Troubleshooting

### Problema: VMs nÃ£o se comunicam
**SoluÃ§Ã£o:**
```bash
# Verificar IPs das VMs
ip addr show

# Testar conectividade
ping <ip-da-outra-vm>

# Verificar firewall
sudo ufw status
sudo ufw allow from <subnet-das-vms>
```

### Problema: Portas nÃ£o acessÃ­veis do Windows
**Verificar:**
1. Redirecionamento configurado no VirtualBox
2. Firewall do Windows
3. ServiÃ§os rodando na VM: `kubectl get svc -n hadoop-cluster`

### Problema: Pods nÃ£o iniciam
**Verificar:**
```bash
# Status dos pods
kubectl get pods -n hadoop-cluster

# Logs de um pod especÃ­fico
kubectl logs <pod-name> -n hadoop-cluster

# Eventos do cluster
kubectl get events -n hadoop-cluster
```

### Problema: Join command nÃ£o funciona
**SoluÃ§Ã£o:**
```bash
# No master, gerar novo token
kubeadm token create --print-join-command

# Usar o novo comando no worker
```

## ğŸ“ Comandos Ãšteis

### Verificar Status do Cluster
```bash
# Nodes do cluster
kubectl get nodes

# Pods do Hadoop
kubectl get pods -n hadoop-cluster

# Services
kubectl get svc -n hadoop-cluster

# Logs em tempo real
kubectl logs -f deployment/spark-master -n hadoop-cluster
```

### Escalar Workers
```bash
# Aumentar rÃ©plicas
kubectl scale deployment spark-worker1 --replicas=3 -n hadoop-cluster
kubectl scale deployment spark-worker2 --replicas=3 -n hadoop-cluster

# Verificar escalonamento
kubectl get pods -n hadoop-cluster -w
```

### Reiniciar Cluster
```bash
# Deletar todos os pods
kubectl delete pods --all -n hadoop-cluster

# Pods serÃ£o recriados automaticamente
```

## ğŸ¯ Resultado Final

**Cluster Kubernetes com:**
- âœ… 1 Master node com Control Plane
- âœ… 2+ Worker nodes
- âœ… Cluster Hadoop/Spark distribuÃ­do
- âœ… Todas as interfaces web funcionando
- âœ… Escalabilidade automÃ¡tica
- âœ… Volumes persistentes
- âœ… Acesso via port forwarding do VirtualBox

**AplicaÃ§Ãµes rodando:**
- ğŸ”¥ Spark Master + History Server
- ğŸ“ HDFS (NameNode + DataNodes)
- ğŸ§µ YARN (ResourceManager + NodeManagers)
- ğŸ““ Jupyter Notebook
- ğŸš€ FastAPI Microservice
- ğŸ“Š Todas as interfaces de monitoramento
